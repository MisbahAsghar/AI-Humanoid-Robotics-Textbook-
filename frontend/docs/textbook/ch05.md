---
title: "Chapter 5: Gazebo Simulation"
sidebar_position: 5
---
# Chapter 5: Gazebo Simulation

**Part**: 3 - Simulation and Virtual Environments
**Estimated Reading Time**: 40-50 minutes
**Estimated Practice Time**: 5-6 hours (including world creation and testing)

---

## Learning Objectives

By the end of this chapter, you will be able to:

**Conceptual Understanding**:
- Explain the role of physics simulation in robotics development
- Describe how physics engines (ODE, Bullet, DART) simulate rigid body dynamics
- Understand collision detection and contact dynamics
- Explain sensor simulation (camera, LiDAR, IMU) and noise modeling
- Differentiate between Gazebo Classic and Gazebo Sim (Ignition)
- Understand SDF (Simulation Description Format) vs. URDF

**Practical Skills**:
- Install and launch Gazebo with ROS 2 Humble
- Create SDF world files with custom environments
- Spawn URDF robots in Gazebo using ros2 commands
- Configure physics engine parameters (gravity, timestep, solver)
- Add and test simulated sensors (camera, LiDAR, IMU)
- Read sensor data from Gazebo via ROS 2 topics
- Implement basic teleoperation for humanoid robots
- Debug common Gazebo errors and performance issues

---

## Prerequisites

**Conceptual Prerequisites**:
- Chapter 3: ROS 2 Fundamentals (topics, launch files)
- Chapter 4: URDF and Robot Modeling (links, joints, sensors)
- Basic understanding of physics (forces, torques, friction, collisions)

**Technical Setup Prerequisites**:
- **ROS 2 Humble** installed
- **Gazebo** (Classic 11 or Gazebo Sim/Ignition)
- **gazebo_ros_pkgs** (ROS 2 integration)
- 8GB RAM minimum (16GB recommended)
- GPU recommended (Intel/NVIDIA/AMD for rendering)

---

## Part 1: Conceptual Foundations (Theory)

### 1.1 What is Gazebo?

**Gazebo** is an open-source 3D robot simulator that provides realistic physics, sensor simulation, and rendering. It's the de facto standard simulator for ROS-based robots.

#### 1.1.1 Why Simulation?

**Advantages of Simulation**:
1. **Safety**: Test dangerous behaviors (falling, collisions) without hardware damage
2. **Speed**: Parallelize testing (run 100 robots simultaneously), faster-than-real-time
3. **Cost**: No hardware required → prototype before building
4. **Reproducibility**: Deterministic tests, version control environments
5. **Accessibility**: Anyone with a computer can develop robot software

**Use Cases**:
- **Algorithm Development**: Test motion planning, control, perception before hardware
- **System Integration**: Validate multi-robot coordination in simulation
- **Training Data Generation**: Synthetic datasets for machine learning (domain randomization)
- **Hardware-in-the-Loop (HIL)**: Simulate sensors, actuate real hardware
- **Education**: Learn robotics without expensive hardware

**Limitations** (Reality Gap):
- **Physics Approximations**: Contact friction, soft bodies, deformable objects imperfect
- **Sensor Fidelity**: Cameras lack lens aberrations, LiDAR lacks multipath effects
- **Actuation**: Motors have perfect control (no backlash, hysteresis, thermal effects)
- **Materials**: Rigid bodies assumption (no flexibility, wear, temperature effects)

**Best Practice**: Simulate early, test on hardware often, iterate.

---

#### 1.1.2 Gazebo Classic vs. Gazebo Sim

| Feature | Gazebo Classic (11) | Gazebo Sim (Ignition → Gazebo) |
|---------|---------------------|-------------------------------|
| **Release** | 2012-2025 (EOL Jan 2025) | 2019-present (active development) |
| **ROS 2 Support** | Via gazebo_ros_pkgs | Native via ros_gz |
| **Physics Engines** | ODE, Bullet, DART, Simbody | ODE, Bullet, DART, TPE (Trivial Physics Engine) |
| **Rendering** | OGRE 1.x | OGRE 2.x, Optix (ray tracing) |
| **Performance** | Single-threaded physics | Multi-threaded physics |
| **Sensors** | Basic plugins | Advanced (GPU-accelerated LiDAR, depth) |
| **Recommended Use** | ROS 2 Humble (2022-2027) | Future ROS 2 distros (Iron+) |

**For This Chapter**: We use **Gazebo Classic 11** (packaged with ROS 2 Humble). Gazebo Sim migration guide provided in optional section.

---

### 1.2 Physics Engines

Gazebo simulates rigid body dynamics using physics engines.

#### 1.2.1 Supported Physics Engines

**1. ODE (Open Dynamics Engine)** - Default in Gazebo Classic
- **Pros**: Stable, well-tested, handles complex contact
- **Cons**: Slower than Bullet, less accurate for stacked objects
- **Use**: General-purpose robotics (manipulation, locomotion)

**2. Bullet**
- **Pros**: Fast, good for parallel contacts (multi-legged robots)
- **Cons**: Less stable for articulated systems (jittery joints)
- **Use**: Wheeled robots, simple manipulators

**3. DART (Dynamic Animation and Robotics Toolkit)**
- **Pros**: Most accurate, supports soft bodies, fast inverse dynamics
- **Cons**: Newer, fewer users, some stability issues
- **Use**: Humanoid locomotion, complex kinematics

**4. Simbody** (deprecated)
- Biomechanics-focused, rarely used in robotics

**Switching Physics Engine** (SDF world file):
```xml
<world name="my_world">
  <physics type="ode">  <!-- or "bullet", "dart" -->
    <max_step_size>0.001</max_step_size>
    <real_time_factor>1.0</real_time_factor>
  </physics>
</world>
```

#### 1.2.2 Physics Parameters

**Key Parameters**:

1. **max_step_size** (default: 0.001s = 1ms)
   - Physics timestep (smaller = more accurate, slower)
   - Rule of thumb: 1/1000 of fastest expected motion frequency
   - Example: Joint at 100 Hz → step size ≤ 0.0001s

2. **real_time_factor**
   - Target simulation speed relative to real-time
   - `1.0` = real-time, `2.0` = 2× faster, `0.5` = slow-motion
   - Actual achieved RTF depends on CPU (check with `gz stats`)

3. **iters** (solver iterations)
   - More iterations = more accurate constraint solving
   - Default ODE: 50, Bullet: 10
   - Increase for stiff constraints (closed kinematic chains)

4. **gravity**
   - Default: `<gravity>0 0 -9.81</gravity>` (m/s², Z up)
   - Change for moon/Mars simulation: `-1.62` (moon), `-3.71` (Mars)

**Example Configuration**:
```xml
<physics type="ode">
  <max_step_size>0.001</max_step_size>
  <real_time_factor>1.0</real_time_factor>
  <max_contacts>20</max_contacts>
  <gravity>0 0 -9.81</gravity>
  <ode>
    <solver>
      <type>quick</type>
      <iters>50</iters>
      <sor>1.3</sor>  <!-- Successive Over-Relaxation -->
    </solver>
  </ode>
</physics>
```

---

### 1.3 Collision Detection and Contact Dynamics

#### 1.3.1 Collision Geometry

**Two Representations**:
1. **Visual**: High-poly meshes for rendering (aesthetics)
2. **Collision**: Simplified geometry for physics (performance)

**Best Practice**: Use primitives (box, cylinder, sphere) for collision when possible → 10-100× faster than mesh collisions.

**Example** (URDF):
```xml
<link name="body">
  <visual>
    <geometry>
      <mesh filename="package://my_robot/meshes/body.dae"/>  <!-- Complex -->
    </geometry>
  </visual>
  <collision>
    <geometry>
      <box size="0.5 0.3 0.2"/>  <!-- Simplified box -->
    </geometry>
  </collision>
</link>
```

#### 1.3.2 Contact Dynamics

**Friction Models**:
- **Coulomb Friction**: $F_f \leq \mu F_n$ (friction force ≤ coefficient × normal force)
  - `<mu1>`, `<mu2>`: Friction along two tangent directions
  - Default: `mu1=1.0, mu2=1.0`
- **Friction Pyramid**: Approximates friction cone with pyramid (faster)

**Contact Parameters** (SDF surface tag):
```xml
<collision name="collision">
  <geometry><box size="1 1 1"/></geometry>
  <surface>
    <friction>
      <ode>
        <mu>1.0</mu>    <!-- Friction coefficient (rubber ~1.0, ice ~0.05) -->
        <mu2>1.0</mu2>
      </ode>
    </friction>
    <contact>
      <ode>
        <kp>1e6</kp>    <!-- Contact stiffness (N/m) -->
        <kd>100</kd>    <!-- Contact damping (N·s/m) -->
      </ode>
    </contact>
    <bounce>
      <restitution_coefficient>0.0</restitution_coefficient>  <!-- 0=inelastic, 1=elastic -->
    </bounce>
  </surface>
</collision>
```

**Typical Values**:
- **Floor**: `mu=1.0` (rubber on concrete), `kp=1e7`, `kd=100`, `restitution=0.0`
- **Ball**: `mu=0.5`, `restitution=0.8` (bouncy)
- **Ice**: `mu=0.05`, `restitution=0.1`

---

### 1.4 Sensor Simulation

Gazebo simulates sensors using plugins that publish to ROS 2 topics.

#### 1.4.1 Camera Sensor

**Simulated Effects**:
- Perspective projection with configurable FOV
- Lens distortion (radial/tangential)
- Gaussian noise on pixel values
- Motion blur (if camera/object moving)

**Limitations**:
- No chromatic aberration, vignetting
- Perfect focus (no depth-of-field blur)
- Simplified lighting (no global illumination)

#### 1.4.2 LiDAR Sensor

**Ray-Based Simulation**:
- Cast rays in scan pattern (360° × vertical FOV)
- GPU-accelerated (can simulate 64-beam LiDAR at 10 Hz in real-time)
- Gaussian noise on range measurements

**Limitations**:
- No multipath reflections (mirrors, glass)
- No atmospheric effects (fog, rain scattering)
- Perfect beam divergence (real LiDAR has ~0.1° spread)

#### 1.4.3 IMU Sensor

**Simulated Measurements**:
- Linear acceleration: $\vec{a} = \vec{a}_{\text{true}} + \vec{n}_a$ (Gaussian noise)
- Angular velocity: $\vec{\omega} = \vec{\omega}_{\text{true}} + \vec{b}_\omega + \vec{n}_\omega$ (bias + noise)
- Orientation: Integrated from angular velocity (with drift)

**Noise Configuration**:
```xml
<imu>
  <angular_velocity>
    <x><noise type="gaussian"><stddev>0.01</stddev></noise></x>
    <!-- ... y, z -->
  </angular_velocity>
  <linear_acceleration>
    <x><noise type="gaussian"><stddev>0.1</stddev></noise></x>
    <!-- ... y, z -->
  </linear_acceleration>
</imu>
```

---

## Part 2: Hands-On Implementation (Practice)

### 2.1 Installing Gazebo with ROS 2

#### 2.1.1 Installation (Ubuntu 22.04, ROS 2 Humble)

```bash
# Install Gazebo Classic 11
sudo apt update
sudo apt install gazebo ros-humble-gazebo-ros-pkgs

# Verify installation
gazebo --version  # Should show 11.x
gz stats  # Check if Gazebo server running

# Install additional tools
sudo apt install ros-humble-gazebo-plugins ros-humble-gazebo-ros-control
```

#### 2.1.2 Test Installation

**Terminal 1**: Launch Gazebo GUI
```bash
gazebo
```

**Expected**: Empty world with ground plane, gray sky.

**Terminal 2**: Check ROS 2 integration
```bash
source /opt/ros/humble/setup.bash
ros2 topic list
# Should see /clock, /gazebo/link_states, /gazebo/model_states
```

**Common Installation Errors**:

**Error 1**: `gazebo: error while loading shared libraries: libgazebo_common.so`
- **Fix**: `sudo apt install --reinstall gazebo`

**Error 2**: `[Err] [REST.cc:205] Unable to connect to `api.ignitionrobotics.org`
- **Cause**: Gazebo tries to download online models
- **Fix**: Ignore (cosmetic warning) or disable: `export GAZEBO_MODEL_DATABASE_URI=""`

**Error 3**: Black screen / GPU not recognized
- **Fix**: Force software rendering: `export LIBGL_ALWAYS_SOFTWARE=1` before `gazebo`

---

### 2.2 Creating a Simple World

#### Overview
Create an SDF world file with ground plane, lighting, and obstacles.

Create file: `~/ros2_ws/src/my_robot_simulation/worlds/simple_world.world`

```xml
<?xml version="1.0"?>
<sdf version="1.6">
  <world name="simple_world">

    <!-- Physics Configuration -->
    <physics type="ode">
      <max_step_size>0.001</max_step_size>
      <real_time_factor>1.0</real_time_factor>
      <real_time_update_rate>1000</real_time_update_rate>
      <gravity>0 0 -9.81</gravity>
    </physics>

    <!-- Lighting -->
    <light name="sun" type="directional">
      <cast_shadows>true</cast_shadows>
      <pose>0 0 10 0 0 0</pose>
      <diffuse>1.0 1.0 1.0 1</diffuse>
      <specular>0.2 0.2 0.2 1</specular>
      <direction>-0.5 0.1 -0.9</direction>
    </light>

    <!-- Ground Plane -->
    <include>
      <uri>model://ground_plane</uri>
    </include>

    <!-- Static Obstacle: Box -->
    <model name="obstacle_box">
      <static>true</static>
      <pose>2 0 0.5 0 0 0</pose>
      <link name="link">
        <collision name="collision">
          <geometry>
            <box><size>1 1 1</size></box>
          </geometry>
        </collision>
        <visual name="visual">
          <geometry>
            <box><size>1 1 1</size></box>
          </geometry>
          <material>
            <ambient>0.8 0.2 0.2 1</ambient>
            <diffuse>0.8 0.2 0.2 1</diffuse>
          </material>
        </visual>
      </link>
    </model>

    <!-- Static Obstacle: Cylinder -->
    <model name="obstacle_cylinder">
      <static>true</static>
      <pose>-2 2 0.5 0 0 0</pose>
      <link name="link">
        <collision name="collision">
          <geometry>
            <cylinder><radius>0.3</radius><length>1.0</length></cylinder>
          </geometry>
        </collision>
        <visual name="visual">
          <geometry>
            <cylinder><radius>0.3</radius><length>1.0</length></cylinder>
          </geometry>
          <material>
            <ambient>0.2 0.8 0.2 1</ambient>
            <diffuse>0.2 0.8 0.2 1</diffuse>
          </material>
        </visual>
      </link>
    </model>

    <!-- Reference Frame (XYZ axes) -->
    <gui>
      <camera>
        <pose>-5 -5 5 0 0.5 0.785</pose>  <!-- Isometric view -->
      </camera>
    </gui>

  </world>
</sdf>
```

**Launch World**:
```bash
gazebo ~/ros2_ws/src/my_robot_simulation/worlds/simple_world.world
```

**Expected**: World with ground, red box at (2, 0), green cylinder at (-2, 2).

---

### 2.3 Spawning a Robot in Gazebo

#### Method 1: Using spawn_entity.py Script

**Step 1**: Launch empty Gazebo world
```bash
# Terminal 1
gazebo --verbose
```

**Step 2**: Spawn robot from URDF (from Chapter 4)
```bash
# Terminal 2
source ~/ros2_ws/install/setup.bash

ros2 run gazebo_ros spawn_entity.py \
  -file ~/ros2_ws/src/my_robot_description/urdf/simple_robot.urdf \
  -entity my_robot \
  -x 0 -y 0 -z 0.5
```

**Parameters**:
- `-file`: Path to URDF file
- `-entity`: Name in Gazebo (must be unique)
- `-x -y -z`: Spawn position (meters)
- `-R -P -Y`: Roll, pitch, yaw (radians)

**Expected**: Robot appears in Gazebo at specified position.

#### Method 2: Including in SDF World

Add to `simple_world.world`:
```xml
<include>
  <uri>model://simple_robot</uri>  <!-- Must be in Gazebo model path -->
  <pose>0 0 0.5 0 0 0</pose>
</include>
```

**Note**: Requires robot in `~/.gazebo/models/` or `GAZEBO_MODEL_PATH`.

---

### 2.4 Reading Simulated Sensor Data

#### Example: Camera Feed

**Step 1**: Ensure robot URDF has camera with Gazebo plugin (Chapter 4, Section 2.4)

**Step 2**: Launch Gazebo with robot
```bash
gazebo --verbose ~/ros2_ws/src/my_robot_simulation/worlds/simple_world.world &
ros2 run gazebo_ros spawn_entity.py -file simple_humanoid_with_camera.urdf -entity humanoid
```

**Step 3**: List camera topics
```bash
ros2 topic list | grep camera
# Expected:
# /simple_humanoid/camera/image_raw
# /simple_humanoid/camera/camera_info
```

**Step 4**: View camera feed
```bash
ros2 run rqt_image_view rqt_image_view /simple_humanoid/camera/image_raw
```

**Expected**: Window showing simulated camera view (Gazebo world from robot's perspective).

**Step 5**: Check publish rate
```bash
ros2 topic hz /simple_humanoid/camera/image_raw
# Expected: ~30 Hz (as configured in URDF plugin)
```

#### Example: LiDAR Scan

**Step 1**: Add LiDAR to URDF (Chapter 4, Section 1.4.2)

**Step 2**: Visualize in RViz
```bash
rviz2
# Add → By topic → /scan → LaserScan
# Set Fixed Frame to "lidar_link" or "base_link"
```

**Expected**: Red points showing obstacles (box, cylinder) detected by LiDAR.

---

### 2.5 Basic Teleoperation

#### Overview
Control robot joints using keyboard teleoperation.

Create file: `~/ros2_ws/src/my_robot_simulation/scripts/teleop_humanoid.py`

```python
#!/usr/bin/env python3
"""
Simple Humanoid Teleoperation
Chapter 5: Gazebo Simulation

Uses keyboard to control humanoid arm joints in Gazebo.
"""

import rclpy
from rclpy.node import Node
from std_msgs.msg import Float64
import sys, select, termios, tty


class HumanoidTeleop(Node):
    def __init__(self):
        super().__init__('humanoid_teleop')

        # Publishers for joint position commands
        self.left_shoulder_pub = self.create_publisher(
            Float64, '/simple_humanoid/left_shoulder_pitch_position_controller/command', 10
        )
        self.left_elbow_pub = self.create_publisher(
            Float64, '/simple_humanoid/left_elbow_position_controller/command', 10
        )
        self.neck_pub = self.create_publisher(
            Float64, '/simple_humanoid/neck_pan_position_controller/command', 10
        )

        # Current joint positions (radians)
        self.left_shoulder = 0.0
        self.left_elbow = 0.0
        self.neck_pan = 0.0

        self.get_logger().info('Humanoid Teleop Started')
        self.print_instructions()

    def print_instructions(self):
        print("""
Humanoid Teleoperation:
  q/a: Left shoulder up/down
  w/s: Left elbow bend/extend
  e/d: Neck pan left/right
  SPACE: Reset to home position
  x: Exit
        """)

    def get_key(self):
        """Get keyboard input (non-blocking)."""
        tty.setraw(sys.stdin.fileno())
        rlist, _, _ = select.select([sys.stdin], [], [], 0.1)
        if rlist:
            key = sys.stdin.read(1)
        else:
            key = ''
        termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self.settings)
        return key

    def update_joint(self, joint_name, delta):
        """Update joint position and publish."""
        if joint_name == 'left_shoulder':
            self.left_shoulder += delta
            self.left_shoulder = max(-3.14, min(3.14, self.left_shoulder))
            msg = Float64()
            msg.data = self.left_shoulder
            self.left_shoulder_pub.publish(msg)
            self.get_logger().info(f'Left Shoulder: {self.left_shoulder:.2f} rad')

        elif joint_name == 'left_elbow':
            self.left_elbow += delta
            self.left_elbow = max(0.0, min(2.356, self.left_elbow))
            msg = Float64()
            msg.data = self.left_elbow
            self.left_elbow_pub.publish(msg)
            self.get_logger().info(f'Left Elbow: {self.left_elbow:.2f} rad')

        elif joint_name == 'neck_pan':
            self.neck_pan += delta
            self.neck_pan = max(-1.57, min(1.57, self.neck_pan))
            msg = Float64()
            msg.data = self.neck_pan
            self.neck_pub.publish(msg)
            self.get_logger().info(f'Neck Pan: {self.neck_pan:.2f} rad')

    def reset_pose(self):
        """Reset all joints to home position."""
        self.left_shoulder = 0.0
        self.left_elbow = 0.0
        self.neck_pan = 0.0
        self.left_shoulder_pub.publish(Float64(data=0.0))
        self.left_elbow_pub.publish(Float64(data=0.0))
        self.neck_pub.publish(Float64(data=0.0))
        self.get_logger().info('Reset to home position')

    def run(self):
        """Main teleoperation loop."""
        self.settings = termios.tcgetattr(sys.stdin)
        delta = 0.1  # Radians per keypress

        try:
            while True:
                key = self.get_key()

                if key == 'q':
                    self.update_joint('left_shoulder', delta)
                elif key == 'a':
                    self.update_joint('left_shoulder', -delta)
                elif key == 'w':
                    self.update_joint('left_elbow', delta)
                elif key == 's':
                    self.update_joint('left_elbow', -delta)
                elif key == 'e':
                    self.update_joint('neck_pan', delta)
                elif key == 'd':
                    self.update_joint('neck_pan', -delta)
                elif key == ' ':
                    self.reset_pose()
                elif key == 'x':
                    break

        except Exception as e:
            self.get_logger().error(f'Error: {e}')
        finally:
            termios.tcsetattr(sys.stdin, termios.TCSADRAIN, self.settings)


def main(args=None):
    rclpy.init(args=args)
    node = HumanoidTeleop()
    node.run()
    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
```

**Note**: This example assumes `ros2_control` controllers are loaded (beyond scope of this chapter; see Chapter 4, Section 3.1 for setup).

**Simplified Alternative**: Use `joint_state_publisher_gui` for manual joint control:
```bash
ros2 run joint_state_publisher_gui joint_state_publisher_gui
```

---

### 2.6 Debugging and Performance

#### Common Gazebo Issues

**Issue 1**: Slow simulation (real-time factor < 1.0)
- **Diagnosis**: Run `gz stats` in terminal, check RTF value
- **Causes**:
  1. Complex collision geometry (use primitives)
  2. Too many contacts (reduce `max_contacts`)
  3. Small timestep (increase `max_step_size` to 0.001-0.002s)
  4. CPU overload (close other apps, use `killall gzserver`)
- **Fix**: Simplify model, reduce sensor rates, disable shadows

**Issue 2**: Robot falls through ground / jittery
- **Cause**: Insufficient physics iterations or low contact stiffness
- **Fix**: Increase `<iters>` to 100, increase contact `<kp>` to 1e7

**Issue 3**: Sensor data not publishing
- **Diagnosis**: `ros2 topic list` doesn't show sensor topic
- **Causes**:
  1. Plugin not loaded (check Gazebo console for errors)
  2. Wrong namespace (check `<ros><namespace>` in URDF)
  3. Gazebo-ROS bridge not running
- **Fix**: Verify plugin filename (`libgazebo_ros_camera.so`), check Gazebo log (`~/.gazebo/server-*.log`)

**Issue 4**: GPU rendering errors (black screen)
- **Fix**: Use software rendering: `export LIBGL_ALWAYS_SOFTWARE=1`

**Performance Monitoring**:
```bash
# Check real-time factor
gz stats -p

# Monitor topics
ros2 topic hz /scan  # Should match sensor update_rate
```

---

## Part 3: Optional Hardware Deployment

### 3.1 Sim-to-Real Transfer Strategies

**Challenge**: Models working in Gazebo often fail on real hardware.

**Common Sim-to-Real Gaps**:
1. **Physics Mismatch**: Simulated friction, inertia, compliance differ from reality
2. **Sensor Mismatch**: Perfect simulated sensors vs. noisy real sensors
3. **Actuator Mismatch**: Instant torque in sim vs. motor dynamics in reality
4. **Environment**: Controlled sim vs. unstructured real world

**Mitigation Strategies**:

**1. Domain Randomization**
- Randomize physics parameters (friction ±20%, mass ±10%, inertia ±15%)
- Randomize sensor noise, lighting, textures
- Forces robustness to parameter uncertainty

**2. System Identification**
- Measure real robot parameters (swing test for inertia, friction tests)
- Update URDF/SDF with measured values

**3. Progressive Deployment**
- Test in sim → test on hardware in safe setup → deploy

**4. Hybrid Sim-Real**
- Simulate hard-to-test scenarios (failures, extreme conditions)
- Validate on real hardware for nominal operations

### 3.2 Hardware-in-the-Loop (HIL)

**Concept**: Connect real sensors/actuators to simulated robot.

**Example**: Real camera, simulated robot
- Mount camera on robot mock-up
- Stream camera feed to ROS 2 topic
- Use simulated robot for planning/control
- **Benefit**: Test vision algorithms with real sensor noise

**Tools**:
- **Gazebo Model Plugin**: Custom plugin to inject real sensor data
- **ROS 2 Bridge**: Replace simulated sensor topic with real camera topic

---

## Review Questions

**Question 1** (Physics Engines): What are the three primary physics engines supported by Gazebo, and when would you choose DART over ODE?

**Question 2** (Collision Geometry): Explain why using simplified collision geometry (box instead of mesh) improves performance. What's the trade-off?

**Question 3** (Sensor Simulation): A simulated LiDAR in Gazebo cannot detect glass walls. Why? How does this affect sim-to-real transfer?

**Question 4** (Performance): Your Gazebo simulation runs at 0.3× real-time (RTF=0.3). List three strategies to improve performance to reach RTF=1.0.

---

## Hands-On Exercises

### Exercise 1: Create a Maze World

**Task**: Create an SDF world file with a maze for robot navigation testing.

**Requirements**:
- 5×5m floor
- 8-10 wall segments (static boxes, 0.1m thick, 1.0m high)
- Start position (green box)
- Goal position (red box)
- Launch with Gazebo, spawn mobile robot

**Solution Guidance**: Duplicate `<model name="wall_1">` blocks, vary `<pose>` tags to create maze pattern.

### Exercise 2: Multi-Sensor Robot

**Task**: Create URDF for robot with camera + LiDAR + IMU, spawn in Gazebo, visualize all sensor data simultaneously in RViz.

**Requirements**:
- Camera: 640×480, 30 FPS, 60° FOV
- LiDAR: 360°, 720 samples, 10 Hz
- IMU: 100 Hz, add Gaussian noise (stddev_accel=0.1, stddev_gyro=0.01)

**Solution Guidance**: Combine Gazebo plugin examples from Chapter 4, Section 1.4. Use RViz with Multi-Camera, LaserScan, and Imu displays.

### Exercise 3: Physics Comparison

**Task**: Spawn same robot in three worlds with different physics engines (ODE, Bullet, DART). Drop robot from 1m height, measure bounce behavior.

**Solution Guidance**:
- Create 3 world files, change `<physics type="ode">` to `bullet`/`dart`
- Launch each, spawn robot at `z=1.0`
- Use `ros2 topic echo /gazebo/link_states` to log position over time
- Compare settling time, bounce height

### Exercise 4: Teleoperation Challenge

**Task**: Implement keyboard teleop for differential drive robot, navigate maze from Exercise 1 without collision.

**Solution Guidance**:
- Publish `Twist` messages to `/cmd_vel` topic
- Subscribe to `/scan` to detect obstacles
- Use `w/s` for forward/backward, `a/d` for rotation
- Add safety: stop if obstacle < 0.5m

---

## Key Takeaways

1. **Gazebo is physics-based simulator**: Uses ODE/Bullet/DART engines for rigid body dynamics, contact forces, friction
2. **Gazebo Classic 11 for ROS 2 Humble**: Recommended version (EOL Jan 2025), Gazebo Sim (Ignition) for future
3. **SDF vs URDF**: SDF describes worlds + robots, URDF describes robots only (auto-converted to SDF in Gazebo)
4. **Physics parameters critical**: `max_step_size` (1ms default), `real_time_factor`, contact stiffness/damping affect accuracy/performance
5. **Collision geometry simplified**: Use primitives (box, cylinder) for physics, high-poly meshes for visuals → 10-100× faster
6. **Sensor simulation**: Camera (perspective projection + noise), LiDAR (ray-casting + Gaussian noise), IMU (acceleration + bias/noise)
7. **Spawning robots**: Use `spawn_entity.py` script or include in SDF world file
8. **ROS 2 integration**: Gazebo publishes sensor data to ROS topics, subscribes to actuator commands
9. **Reality gap exists**: Simulation approximates physics (friction, contact, sensors) → test on hardware early and often
10. **Sim-to-real strategies**: Domain randomization, system identification, progressive deployment, hardware-in-the-loop

---

## References

(References to be provided in separate file)

---

## Answer Key

**Answer 1**: Three engines: **ODE** (default, stable, good contact), **Bullet** (fast, parallel contacts), **DART** (accurate, inverse dynamics, soft bodies). Choose **DART over ODE** for humanoid locomotion requiring accurate joint torques, contact force estimation, or soft body simulation (e.g., deformable feet). DART also handles closed kinematic chains better.

**Answer 2**: Simplified collision geometry (box) has **far fewer vertices** than mesh (e.g., 8 vertices for box vs. 1000+ for mesh) → collision detection algorithms (GJK, SAT) compute distances/intersections faster. **Trade-off**: Less accurate contact (box may not match visual shape) → robot may collide with objects that look farther away, or vice versa. Acceptable for most robots where rough contact approximation sufficient.

**Answer 3**: Gazebo LiDAR uses **ray-casting**: shoots rays, returns first intersection with collision geometry. Glass walls are **transparent objects** often modeled without collision geometry (to allow seeing through) → rays pass through without detecting. **Sim-to-real impact**: Algorithms relying on LiDAR to detect glass (windows, display cases) will fail on real robot. **Mitigation**: Add invisible collision geometry for glass in simulation, or use camera-based detection.

**Answer 4**: Three strategies to improve RTF from 0.3 to 1.0:
1. **Simplify collision geometry**: Replace mesh collisions with primitives (box, cylinder) → 10-100× faster contact detection
2. **Increase timestep**: Change `max_step_size` from 0.001s to 0.002s → 2× fewer physics updates (trade-off: less accurate)
3. **Reduce sensor rates**: Lower camera FPS (30→10), LiDAR Hz (10→5) → less rendering/data publishing overhead
Bonus: Disable shadows (`<cast_shadows>false</cast_shadows>`), reduce `max_contacts`, switch to Bullet engine

---

**End of Chapter 5**

**Next Chapter Preview**: Chapter 6 will cover Unity-based digital twins, comparing Unity vs. Gazebo, photorealistic rendering, and ML-Agents integration for reinforcement learning.

---

**Last Updated**: 2025-12-23
**Tested On**: Ubuntu 22.04, ROS 2 Humble, Gazebo Classic 11
